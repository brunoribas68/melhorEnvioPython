{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77713d76",
   "metadata": {},
   "source": [
    " # Teste Melhor Envio\n",
    " ### Requisitos\n",
    "###### Processar o arquivo de log, extrair informações e salvá-las no banco de dados.\n",
    "###### Gerar um relatório para cada descrição abaixo, em formato csv:\n",
    "###### Requisições por consumidor;\n",
    "###### Requisições por serviço;\n",
    "###### Tempo médio de request , proxy e gateway por serviço.\n",
    "###### Documentar passo a passo de como executar o teste através de um arquivo\n",
    "###### README.md .\n",
    "###### Efetue o commit de todos os passos do desenvolvimento em um git público de sua\n",
    "###### preferência e disponibilize apenas o link para o repositório."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "df516306",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-16 06:23:32,024 INFO sqlalchemy.engine.Engine SELECT DATABASE()\n",
      "2022-06-16 06:23:32,025 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2022-06-16 06:23:32,026 INFO sqlalchemy.engine.Engine SELECT @@sql_mode\n",
      "2022-06-16 06:23:32,027 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2022-06-16 06:23:32,028 INFO sqlalchemy.engine.Engine SELECT @@lower_case_table_names\n",
      "2022-06-16 06:23:32,029 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2022-06-16 06:23:32,031 INFO sqlalchemy.engine.Engine SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = %(table_schema)s AND table_name = %(table_name)s\n",
      "2022-06-16 06:23:32,032 INFO sqlalchemy.engine.Engine [generated in 0.00078s] {'table_schema': 'melhorenvio', 'table_name': 'latencies'}\n",
      "2022-06-16 06:23:32,034 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-06-16 06:23:32,035 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE latencies (\n",
      "\tproxy BIGINT, \n",
      "\tkong BIGINT, \n",
      "\trequest BIGINT, \n",
      "\tservice_id TEXT, \n",
      "\tconsumer_id TEXT, \n",
      "\tclient_ip TEXT, \n",
      "\troute TEXT\n",
      ")\n",
      "\n",
      "\n",
      "2022-06-16 06:23:32,035 INFO sqlalchemy.engine.Engine [no key 0.00046s] {}\n",
      "2022-06-16 06:23:32,680 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2022-06-16 06:23:32,755 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-06-16 06:23:33,489 INFO sqlalchemy.engine.Engine INSERT INTO latencies (proxy, kong, request, service_id, consumer_id, client_ip, route) VALUES (%(proxy)s, %(kong)s, %(request)s, %(service_id)s, %(consumer_id)s, %(client_ip)s, %(route)s)\n",
      "2022-06-16 06:23:33,490 INFO sqlalchemy.engine.Engine [generated in 0.62063s] ({'proxy': 1836, 'kong': 8, 'request': 1058, 'service_id': 'c3e86413-648a-3552-90c3-b13491ee07d6', 'consumer_id': '72b34d31-4c14-3bae-9cc6-516a0939c9d6', 'client_ip': '75.241.168.121', 'route': '0636a119-b7ee-3828-ae83-5f7ebbb99831'}, {'proxy': 1727, 'kong': 10, 'request': 2185, 'service_id': 'd035ffcf-914a-3007-b028-ae18f04d75b4', 'consumer_id': 'f643db14-a82d-30c2-8c13-889db1d0fcc2', 'client_ip': '88.248.178.118', 'route': '7bedb816-c359-3b8c-a0f9-b03b46c63402'}, {'proxy': 896, 'kong': 9, 'request': 2129, 'service_id': 'a5bf08bd-c030-30d5-8009-83a8c30103bf', 'consumer_id': 'beceaa24-823b-3bf9-9ae6-c8dada26b264', 'client_ip': '56.54.196.221', 'route': '9bb5b399-23b4-3c5a-b92b-2febdbcfa4e4'}, {'proxy': 1209, 'kong': 12, 'request': 1274, 'service_id': '22f8e3a6-01f7-3264-b4b5-9d178df11d06', 'consumer_id': '7ba24e1f-ed19-31b2-a4be-4114721d63af', 'client_ip': '164.83.216.199', 'route': '2c31902e-00af-30aa-a04f-08c50ed55785'}, {'proxy': 1708, 'kong': 20, 'request': 2244, 'service_id': '22f8e3a6-01f7-3264-b4b5-9d178df11d06', 'consumer_id': '1696f3c4-7732-38f2-9ba8-0eeca8df05d7', 'client_ip': '154.78.181.43', 'route': '2c31902e-00af-30aa-a04f-08c50ed55785'}, {'proxy': 1327, 'kong': 16, 'request': 1416, 'service_id': 'a5bf08bd-c030-30d5-8009-83a8c30103bf', 'consumer_id': '79b8acdd-9704-346b-9016-284994165b4d', 'client_ip': '91.95.172.182', 'route': '9bb5b399-23b4-3c5a-b92b-2febdbcfa4e4'}, {'proxy': 1852, 'kong': 11, 'request': 1837, 'service_id': 'c3e86413-648a-3552-90c3-b13491ee07d6', 'consumer_id': 'd83ff610-3461-36d7-be57-7e909cfce8b8', 'client_ip': '220.174.132.132', 'route': '0636a119-b7ee-3828-ae83-5f7ebbb99831'}, {'proxy': 1736, 'kong': 18, 'request': 1552, 'service_id': 'a5bf08bd-c030-30d5-8009-83a8c30103bf', 'consumer_id': 'a265b105-379c-3ac3-b9ce-d2587a745468', 'client_ip': '91.164.56.149', 'route': '9bb5b399-23b4-3c5a-b92b-2febdbcfa4e4'}  ... displaying 10 of 100000 total bound parameter sets ...  {'proxy': 1264, 'kong': 18, 'request': 2458, 'service_id': '22f8e3a6-01f7-3264-b4b5-9d178df11d06', 'consumer_id': 'aac8d101-c4b5-3fd6-8833-b0fba8f36587', 'client_ip': '54.231.110.76', 'route': '2c31902e-00af-30aa-a04f-08c50ed55785'}, {'proxy': 1807, 'kong': 9, 'request': 2318, 'service_id': 'a5bf08bd-c030-30d5-8009-83a8c30103bf', 'consumer_id': '6763ff2b-3a3d-30b5-a365-2835597b848d', 'client_ip': '66.195.97.68', 'route': '9bb5b399-23b4-3c5a-b92b-2febdbcfa4e4'})\n",
      "2022-06-16 06:23:40,508 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "def ImportLog():\n",
    "    return pd.read_json('logs.txt', lines=True)\n",
    "\n",
    "\n",
    "def OrganizaDataFrame(dados):\n",
    "    # organizando o lantencia pois ele que usaremos para os relatorios\n",
    "    dados['latencies']['service_id'] = dados['services'].id\n",
    "    dados['latencies']['consumer_id'] = dados['authenticated_entity']\n",
    "    dados['latencies']['client_ip'] = dados['client_ip']\n",
    "    dados['latencies']['route'] = dados['routes'].id\n",
    "\n",
    "    #dizendo par ao DataFrame que o id é o index de routes\n",
    "    dados['routes'].set_index('id', inplace=True)\n",
    "\n",
    "    # renomeando a coluna para que não tenha .\n",
    "    dados['routes'].rename(columns={'service.id': 'service_id'}, inplace=True)\n",
    "\n",
    "    # os pop's a seguir são para limpar variaveis que os dados se repetem\n",
    "    # para descobrir quais são fiz um:\n",
    "    # new_data_frame[nomeDoDataFrame][headerQueValidei].value_counts()\n",
    "    dados['requests'].drop(['headers.user-agent', 'uri', 'querystring', 'headers.accept'], axis=1, inplace=True)\n",
    "    dados['routes'].drop(['regex_priority', 'preserve_host', 'strip_path', 'protocols', 'paths', 'methods'],\n",
    "                         axis=1, inplace=True)\n",
    "    dados['services'].drop(['path', 'port', 'protocol', 'read_timeout', 'retries', 'write_timeout', 'connect_timeout'],\n",
    "                           axis=1, inplace=True)\n",
    "    return dados\n",
    "\n",
    "\n",
    "def ArrumaJson(data_frame):\n",
    "    # criação do novo dataframe com os dados convertidos de json para dataframe\n",
    "    # iniciamente pensei em gravar todos esses dados no banco\n",
    "    # porem fui informado que não era necessario\n",
    "    new_data_frame = {\n",
    "        'latencies': pd.json_normalize(data_frame.latencies),\n",
    "        'requests': pd.json_normalize(data_frame.request),\n",
    "        'responses': pd.json_normalize(data_frame.response),\n",
    "        'authenticated_entity': pd.json_normalize(data_frame.authenticated_entity),\n",
    "        'routes': pd.json_normalize(data_frame.route),\n",
    "        'services': pd.json_normalize(data_frame.service),\n",
    "        'client_ip': data_frame.client_ip,\n",
    "        'upstream_uri': data_frame.upstream_uri,\n",
    "        'started_at': data_frame.started_at\n",
    "    }\n",
    "\n",
    "    return OrganizaDataFrame(new_data_frame)\n",
    "\n",
    "\n",
    "def RelatorioConsumidor(consumers):\n",
    "    # organizar por consumidor\n",
    "    relatorio_por_consumidor = consumers.groupby(by='consumer_id')\n",
    "    csv = {}\n",
    "    os.makedirs('customers', exist_ok=True)\n",
    "    for customer, dados in relatorio_por_consumidor:\n",
    "        csv[customer] = dados\n",
    "        csv[customer].to_csv(f\"./customers/{customer}.csv\", sep=\";\")\n",
    "    return relatorio_por_consumidor\n",
    "\n",
    "\n",
    "def RelatorioServico(servico):\n",
    "    # organizar por serviço\n",
    "    relatorio_por_servico = new_data_frame['services'].groupby(by='id')\n",
    "    csv = {}\n",
    "    os.makedirs('services', exist_ok=True)\n",
    "    for services, dados in relatorio_por_servico:\n",
    "        csv[services] = dados\n",
    "        csv[services].to_csv(f\"./services/{dados.iloc[0]['name']}.csv\", sep=\";\")\n",
    "    return relatorio_por_servico\n",
    "\n",
    "\n",
    "def RelatorioMediaLatencia(latencies):\n",
    "    # organizar pelo consumidor com as médias\n",
    "    relatorio_medias_consumidor = latencies.groupby('consumer_id').mean()\n",
    "    relatorio_medias_consumidor.to_csv('relatorio_medias_consumidor.csv', sep=';')\n",
    "    return relatorio_medias_consumidor\n",
    "\n",
    "\n",
    "def CriarBase(base):\n",
    "    engine = create_engine(f\"mysql+pymysql://{os.getenv('USER_NAME')}:{os.getenv('USER_PASSWORD')}@\"\n",
    "                           f\"{os.getenv('HOST_NAME')}/{os.getenv('DATABASE')}\", echo=True)\n",
    "    # para o proposito dessa atividade deixei para que ele recrie a base se ela já existir\n",
    "    # acredito que esse não seja o recomendado, porem para o objetivo da tarefa é o mais indicado\n",
    "    new_data_frame['routes'].to_sql('routes',engine, if_exists='replace', index=False, index_label='id')\n",
    "    new_data_frame['request'].to_sql('requests',engine, if_exists='replace', index=True, index_label='request')\n",
    "    new_data_frame['latencies'].to_sql('latencies',engine, if_exists='replace', index=False, index_label='id')\n",
    "    new_data_frame['services'].to_sql('services',engine, if_exists='replace', index=False, index_label='id')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    load_dotenv()\n",
    "    data_frame = ImportLog()\n",
    "    new_data_frame = ArrumaJson(data_frame)\n",
    "    RelatorioConsumidor(new_data_frame['latencies'])\n",
    "    RelatorioServico(new_data_frame['latencies'])\n",
    "    RelatorioMediaLatencia(new_data_frame['latencies'])\n",
    "    CriarBase(new_data_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "620d1f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sauer\n",
      "orn\n",
      "ritchie\n",
      "terry\n",
      "corkery\n"
     ]
    }
   ],
   "source": [
    "# new_data_frame['latencies'].drop(['service_id','consumer_id'], axis = 1, inplace=True)\n",
    "relatorio_por_servico = new_data_frame['services'].groupby(by='id')\n",
    "csv = {}\n",
    "os.makedirs('services', exist_ok=True)\n",
    "for services, dados in relatorio_por_servico:\n",
    "    print(dados.iloc[0]['name'])\n",
    "#new_data_frame['services']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
